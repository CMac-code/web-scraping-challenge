# To add a new cell, type '# %%'
# To add a new markdown cell, type '# %% [markdown]'
# %%
# Dependencies
from splinter import Browser
from bs4 import BeautifulSoup as bs
import time
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd
import codecs


# %%
# Set path
executable_path = {'executable_path': ChromeDriverManager().install()}
browser = Browser("chrome", **executable_path, headless=False)

# %% [markdown]
# ### NASA Mars News
# 
# * Scrape the [Mars News Site](https://redplanetscience.com) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later.
# 

# %%
# Visit the NASA Mars News Site
url = "https://redplanetscience.com"
browser.visit(url)


# %%
html = browser.html
news_soup = bs(html, "html.parser")
articles = news_soup.find_all('div', class_='col-md-8')


# %%
for article in articles:
    news_title = article.find('div', class_='content_title').text
    news_p = article.find('div', class_='article_teaser_body').text

    print(news_title)
    print(news_p)

    break

# %% [markdown]
# ### JPL Mars Space Images - Featured Image
# 
# * Visit the url for the Featured Space Image page [here](https://spaceimages-mars.com).
# 
# * Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.
# 
# * Make sure to find the image url to the full size `.jpg` image.
# 
# * Make sure to save a complete url string for this image.

# %%
url2 = 'https://spaceimages-mars.com/'
browser.visit(url2)


# %%
html = browser.html
soup = bs(html, 'html.parser')
images = soup.find_all('a', class_='fancybox-thumbs')


# %%
for image in images:
    featured_image_url = f"https://spaceimages-mars.com/{image['href']}"

    print(featured_image_url)

    break

# %% [markdown]
# ### Mars Facts
# 
# * Visit the Mars Facts webpage [here](https://galaxyfacts-mars.com) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.
# 
# * Use Pandas to convert the data to a HTML table string.

# %%
url3 = 'https://galaxyfacts-mars.com/'
#browser.visit(url3)


# %%
table = pd.read_html(url3)
mars_df = table[0]

# %% [markdown]
# 

# %%
col = [mars_df.iloc[0][x] for x in range(len(mars_df.iloc[0]))] 
mars_df.columns = col
mars_df=mars_df.iloc[1:,:]


# %%
mars_df.to_html('templates/mars_facts.html', index=False)


# %%
file = codecs.open("templates/mars_facts.html", "r", "utf-8")
mars_facts=file.read()

# %% [markdown]
# ### Mars Hemispheres
# 
# * Visit the Astrogeology site [here](https://marshemispheres.com) to obtain high resolution images for each of Mar's hemispheres.
# 
# * You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.
# 
# * Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.
# 
# * Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.

# %%
url4 = 'https://marshemispheres.com'
browser.visit(url4)


# %%
html = browser.html
soup = bs(html, 'html.parser')
links = soup.find_all('div', class_="description")


# %%
hem_img_urls = []
hem_titles = []


# %%
for link in links:
# Use Beautiful Soup's find() method to navigate and retrieve attributes 
    url_string = link.a['href'] 
    hem_img_urls.append(f"https://marshemispheres.com/{url_string}") 
    title_string= link.a.h3.text 
    hem_titles.append(title_string)

    print(title_string)
    print('https://marshemispheres.com/' + url_string)


# %%
print(hem_img_urls)
print(hem_titles)


# %%
img_list = []

for urls in hem_img_urls: 
    url = urls

    browser.visit(url)
    html = browser.html
    soup = bs(html, 'html.parser')


    hem_imgs = soup.find_all('ul') 
    img_list.append(f"https://galaxyfacts-mars.com/{hem_imgs[0].find('a')['href']}")


# %%
hemisphere_urls = [
    {"title": hem_titles[0], "img_url": img_list[0]},
    {"title": hem_titles[1], "img_url": img_list[1]},
    {"title": hem_titles[2], "img_url": img_list[2]},
    {"title": hem_titles[3], "img_url": img_list[3]},]

browser.quit()


# %%
mars_df


# %%
m_data= {
    "news_title":news_title,
    "news_p":news_p,
    "featured_image_url":featured_image_url,
    "mars_fact":mars_facts,
    "hemisphere_image_urls":hem_img_urls
    }


